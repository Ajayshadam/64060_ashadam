---
title: "FML Assignment -2"
author: "Ajay Shadam"
date: "2023-10-21"
output:
  pdf_document: default
  html_document: default
---

## summary
Problem statement:

Summary
Problem Statement
Universal bank is a young bank growing rapidly in terms of overall customer acquisition. The majority of
these customers are liability customers (depositors) with varying sizes of relationship with the bank. The
customer base of asset customers (borrowers) is quite small, and the bank is interested in expanding this base
rapidly in more loan business. In particular, it wants to explore ways of converting its liability customers to
personal loan customers.
A campaign that the bank ran last year for liability customers showed a healthy conversion rate of over
9% success. This has encouraged the retail marketing department to devise smarter campaigns with better
target marketing. The goal is to use k-NN to predict whether a new customer will accept a loan offer. This
will serve as the basis for the design of a new campaign.
The file UniversalBank.csv contains data on 5000 customers. The data include customer demographic
information (age, income, etc.), the customer’s relationship with the bank (mortgage, securities account,
etc.), and the customer response to the last personal loan campaign (Personal Loan). Among these 5000
customers, only 480 (= 9.6%) accepted the personal loan that was offered to them in the earlier campaign.
Partition the data into training (60%) and validation (40%) sets

```{r}
###Data Import and Cleaning

 #firstly install and load  the pacakges “class”,“caret”,“e1071”
library(class)
library(caret)
```
```{r}
##Reading the data 
A_data <- read.csv("C:/Users/Ajay Reddy/Downloads/UniversalBank (1).csv")
dim(A_data)
```
```{r}
head(A_data)
```

```{r}
tail(A_data)
```
```{r}
t(t(names(A_data))) ## The dataframe is transposed using the t function.
```
```{r}
getwd()
```
```{r}
#Drop ID and ZIP
Anew_data <- A_data[,-c(1,5)]
dim(Anew_data)
```
#Split Data into 60% training and 40% validation. There are many ways to do this. We will look at 2different ways. Before we split, let us transform categorical variables into dummy variables

#changing the education attribute's int value to char
```{r}
Anew_data$Education <- as.factor(Anew_data$Education)

```
#constructing the dummy variables for the attribute "education"
```{r}
dums<- dummyVars(~.,data=Anew_data)
A_data <- as.data.frame(predict(dums,Anew_data))
```

#Setting the seed and partitioning the data into training (60%) and validation (40%) sets is necessary since we must run the function again.

```{r}
set.seed(1)
trains_data <- sample(row.names(A_data), 0.6*dim(A_data)[1])
valida_data <- setdiff(row.names(A_data),trains_data)
train <- A_data[trains_data,]
valid <- A_data[valida_data,]
t(t(names(train)))
```
```{r}
summary(train)
```

```{r}
cat("The size of the training dataset is:",nrow(train))

```
```{r}
summary(valid)

```

```{r}
cat("The size of the validation dataset is:",nrow(valid))
```
##Now, let us normalize the data

```{r}
trains_norm <- train[,-10]
valida_norm <- valid[,-10]
norm <- preProcess(train[,-10],method=c("center","scale"))
5
trains_norm <- predict(norm,train[,-10])
valida_norm <- predict(norm,valid[,-10])

```
Questions
Consider the following customer:
1. Age = 40, Experience = 10, Income = 84, Family = 2, CCAvg = 2, Education_1 = 0, Education_2 = 1, Education_3 = 0, Mortgage = 0, Securities
Account = 0, CD Account = 0, Online = 1, and Credit Card = 1. Perform
a k-NN classification with all predictors except ID and ZIP code using k = 1.
Remember to transform categorical predictors with more than two categories
into dummy variables first. Specify the success class as 1 (loan acceptance), and
use the default cutoff value of 0.5. How would this customer be classified?


Creating new customer data

```{r}
new_custo <- data.frame(
Age = 40,
Experience = 10,
Income = 84,
Family = 2,
CCAvg = 2,
Education.1 = 0,
Education.2 = 1,
Education.3 = 0,
Mortgage = 0,
Securities.Account = 0,
CD.Account = 0,
Online = 1,
CreditCard = 1
)

# Normalize the new customer dataset
cust.norm <- predict(norm, new_custo)

```

Performing kNN classification

```{r}
prediction <- class::knn(train = trains_norm,
test = cust.norm,
cl = train$Personal.Loan, k = 1)
prediction

```

2.What is a choice of k that balances between overfitting and ignoring the predictor information?

```{r}
# Calculate the accuracy for each value of k
# Set the range of k values to consider
accuracy <- data.frame(k = seq(1, 15, 1), overallaccuracy = rep(0, 15))
for(i in 1:15) {
kn <- class::knn(train = trains_norm,
test = valida_norm,
cl = train$Personal.Loan, k = i)
accuracy[i, 2] <- confusionMatrix(kn,
as.factor(valid$Personal.Loan),positive = "1")$overall[1]
}
which(accuracy[,2] == max(accuracy[,2]))
```
```{r}
accuracy
```
Among the k values from 1 to 15, 3 is the best performer.The most accurate for 3 is this k, which strikes a compromise between overfitting and disregarding forecasts.

```{r}
plot(accuracy$k,accuracy$overallaccuracy)
```
 3. Show the confusion matrix for the validation data that results from using the best k.
 

confusion matrix

```{r}
pred <- class::knn(train = trains_norm,
test = valida_norm,
cl = train$Personal.Loan, k=3)
confusionMatrix(pred,as.factor(valid$Personal.Loan))
```

4. Consider the following customer: Age = 40, Experience = 10, Income =
84,Family = 2, CCAvg = 2, Education_1 = 0, Education_2 = 1, Education_3
= 0,Mortgage = 0, Securities Account = 0, CD Account = 0, Online = 1 and
CreditCard = 1. Classify the customer using the best k.


#Make the same column names in a data frame for the  client 2 .
```{r}
custo2 <- data.frame(
Age = 40,
Experience = 10,
Income = 84,
Family = 2,
CCAvg = 2,
Education.1 = 0,
Education.2 = 1,
Education.3 = 0,
Mortgage = 0,
Securities.Account = 0,
CD.Account = 0,
Online = 1,
CreditCard = 1)

#Normalizing the 2nd client dataset
cust2_norm <- predict(norm , custo2)
```

5. Repeating the process by partitioning the data into three parts -
50%, 30%, 20%,Apply the k-NN method with the k chosen above. Compare the
confusion matrix of the test set with that of the training and validation sets.
Comment on the differences and their reason.

```{r}
set.seed(500)
Trains_Index <- sample(row.names(A_data), .5*dim(A_data)[1])#create train index
9
#create validation index
Valid_Index <- sample(setdiff(row.names(A_data),Trains_Index),.3*dim(A_data)[1])
Test_Index =setdiff(row.names(A_data),union(Trains_Index,Valid_Index))#create test index
train.df <- A_data[Trains_Index,]
cat("The size of the new training dataset is:", nrow(train.df))

valid.df <- A_data[Valid_Index, ]
cat("The size of the new validation dataset is:", nrow(valid.df))

test.df <- A_data[Test_Index, ]
cat("The size of the new test dataset is:", nrow(test.df))

```
Normalizing the data

```{r}
norms_values <- preProcess(train.df[, -10], method=c("center", "scale"))
train.df.norm <- predict(norm, train.df[, -10])
valid.df.norm <- predict(norm, valid.df[, -10])
test.df.norm <- predict(norm ,test.df[,-10])
```

Performing kNN and creating confusion matrix on training, testing, validation
data

```{r}
predic3 <- class::knn(train = train.df.norm,
test = test.df.norm,
cl = train.df$Personal.Loan, k=3)
confusionMatrix(predic3,as.factor(test.df$Personal.Loan))
```
```{r}
predic4 <- class::knn(train = train.df.norm,
test = valid.df.norm,
cl = train.df$Personal.Loan, k=3)
confusionMatrix(predic4,as.factor(valid.df$Personal.Loan))
```
```{r}
predic5 <- class::knn(train = train.df.norm,
test = train.df.norm,
cl = train.df$Personal.Loan, k=3)
confusionMatrix(predic5,as.factor(train.df$Personal.Loan))
```

